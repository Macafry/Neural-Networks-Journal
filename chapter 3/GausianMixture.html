<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>gausianmixture</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="GausianMixture_files/libs/clipboard/clipboard.min.js"></script>
<script src="GausianMixture_files/libs/quarto-html/quarto.js"></script>
<script src="GausianMixture_files/libs/quarto-html/popper.min.js"></script>
<script src="GausianMixture_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="GausianMixture_files/libs/quarto-html/anchor.min.js"></script>
<link href="GausianMixture_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="GausianMixture_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="GausianMixture_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="GausianMixture_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="GausianMixture_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Gaussian Mixture Models</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>So far we’ve covered 3 of the 4 pillars of machine learning: regression, classification, and dimension reduction. This section focuses on the fourth pillar: density estimation.</p>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">Definition</h2>
<p>Many datasets can’t be model with a single basic distribution as shown in the picture below:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/GMM-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>Instead of trying to fit a single distribution to the data that won’t provide a good fit, we can use a <strong>mixture model</strong>. A mixture model is a convex combination of <span class="math inline">\(K\)</span> simple distributions, like a normal or a uniform distribution.</p>
<p><span class="math display">\[
p_\text{Mixture}(x) = \sum_{k=1}^K \pi_i p_k(x)  \quad \text{with} \quad \pi_k \in [0,1] \quad \text{and} \quad \sum_{k=1}^K \pi_k = 1
\]</span></p>
<p>A specific case of mixture model is the <strong>Gaussian Mixture Model (GMM)</strong>, which is a mixture of <span class="math inline">\(K\)</span> Gaussian distributions. The formula is as follows:</p>
<p><span class="math display">\[
p_\text{GMM}(x \mid \theta) = \sum_{k=1}^K \pi_k \mathcal{N}(x \mid \mu_k, \Sigma_k) \quad \text{with} \quad \theta = \{ \pi_k, \mu_k, \Sigma_k \}_{k=1}^K
\]</span></p>
<p>The following image represents a GMM with 3 components:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/GMM-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>With the formula:</p>
<p><span class="math display">\[
p_\text{GMM}(x \mid \theta) = \textcolor{blue}{0.5 \mathcal{N}(x \mid -2, \frac{1}{2})} +
\textcolor{orange}{0.2 \mathcal{N}(x \mid 1, 2)} +
\textcolor{green}{0.3 \mathcal{N}(x \mid 4, 1)}
\]</span></p>
<p>In this case, the colors of the formula match the colors of their corresponding components in the image. This shows that a GMM can be used to represented complex distributions with multiple peaks.</p>
</section>
<section id="em-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="em-algorithm">EM Algorithm</h2>
<p>We can use the <strong>EM algorithm</strong> to fit a Maximum Likelihood Gaussian Mixture model. The EM algorithm consists of two steps: the Expectation step (E-step) and the Maximization step (M-step).</p>
<p>Before we start, let’s define some notation:</p>
<ul>
<li><span class="math inline">\(x\)</span> is the observed data.</li>
<li><span class="math inline">\(N\)</span> is the number of data points.</li>
<li><span class="math inline">\(\mu_k\)</span> is the mean of the k-th Gaussian component.</li>
<li><span class="math inline">\(\Sigma_k\)</span> is the covariance matrix of the k-th Gaussian component.</li>
<li><span class="math inline">\(\pi_k\)</span> is the mixing coefficient of the k-th Gaussian component.</li>
<li><span class="math inline">\(r_{nk}\)</span> is the responsibility of the k-th Gaussian component for the n-th data point, with the following formula: <span class="math display">\[
r_{nk} = \dfrac{\pi_k \mathcal{N}(x_n \mid \mu_k, \Sigma_k)}{\sum_{k=1}^K \pi_k \mathcal{N}(x_n \mid \mu_k, \Sigma_k)}
\]</span></li>
<li><span class="math inline">\(N_k = \sum_{n=1}^N r_{nk}\)</span> is the total responsibility for the k-th Gaussian component.</li>
</ul>
<p>The following identities follow from the definition of <span class="math inline">\(r_{nk}\)</span>:</p>
<ul>
<li><span class="math inline">\(\sum_{k=i}^K r_{nk} = 1\)</span> for all <span class="math inline">\(n\)</span>.</li>
<li><span class="math inline">\(\sum_{n=1}^N r_{nk} = N_k\)</span> for all <span class="math inline">\(k\)</span>.</li>
<li><span class="math inline">\(\sum_{k=i}^K N_k = N\)</span></li>
<li><span class="math inline">\(\sum_{k=i}^K \sum_{k=i}^K r_{nk} = N\)</span></li>
</ul>
<p>Now we can use the following steps to fit a Gaussian Mixture Model using the EM algorithm:</p>
<ol type="1">
<li><p>Initialize the parameters <span class="math inline">\(\mu_k\)</span>, <span class="math inline">\(\Sigma_k\)</span>, and <span class="math inline">\(\pi_k\)</span> randomly.</p></li>
<li><p><strong>E-step</strong>: Compute the responsibilities <span class="math inline">\(r_{nk}\)</span> for all <span class="math inline">\(n\)</span> and <span class="math inline">\(k\)</span>. Use the formula above.</p></li>
<li><p><strong>M-step</strong>: Update the parameters <span class="math inline">\(\mu_k\)</span>, <span class="math inline">\(\Sigma_k\)</span>, and <span class="math inline">\(\pi_k\)</span> using the following formulas:</p>
<ul>
<li><p><span class="math inline">\(\mu_k^\text{new} = \dfrac{1}{N_k} \sum_{n=1}^N r_{nk} x_n\)</span> - weighted average of the data points for the k-th Gaussian component based on the responsibilitues.</p></li>
<li><p><span class="math inline">\(\Sigma_k^\text{new} = \dfrac{1}{N_k} \sum_{n=1}^N r_{nk} (x_n - \mu_k)(x_n - \mu_k)^T\)</span> - weighted covariance matrix of the data points for the k-th Gaussian component based on the responsibilities.</p></li>
<li><p><span class="math inline">\(\pi_k^\text{new} = \dfrac{N_k}{N}\)</span> - proportion of total responsibilities that belong to the k-th Gaussian component.</p></li>
</ul>
<p>While these updates look heuristic, they’re supported by Maximum Likelihood Estimation.</p></li>
<li><p>Repeat steps 2 and 3 (EM) until convergence.</p></li>
</ol>
</section>
<section id="applications-of-gaussian-mixture-models" class="level2">
<h2 class="anchored" data-anchor-id="applications-of-gaussian-mixture-models">Applications of Gaussian Mixture Models</h2>
<section id="latent-variables" class="level4">
<h4 class="anchored" data-anchor-id="latent-variables">Latent variables</h4>
<p>We can re-interpret a Gaussian Mixture Model as latent feature encoder, where <span class="math inline">\(z_n\)</span> is the latent feature vector for the <span class="math inline">\(n\)</span>-th data point. This latent variable is typically defined as <span class="math inline">\(z_n = (r_n1, r_n2, \cdots, r_nK)\)</span>*, a probability vector that indicates the probability that the <span class="math inline">\(n\)</span>-th data point belongs to each of the <span class="math inline">\(K\)</span> distributions. In other words, it indicated “belongedness” to each distributions. Note that this is an unsupervised learning algorithm, so we don’t know the true labels of the data points.</p>
<p>*The formula for <span class="math inline">\(z_n\)</span> can be proven using Bayes’ Theorem.</p>
</section>
<section id="stochasitic-clustering" class="level4">
<h4 class="anchored" data-anchor-id="stochasitic-clustering">Stochasitic Clustering</h4>
<p>A Gaussian Mixture model can be interpreted as a probabilistic clustering algorithm, where <span class="math inline">\(r_{nk}\)</span> is the probability that the <span class="math inline">\(n\)</span>-th data point belongs to the <span class="math inline">\(k\)</span>-th cluster. Funilly enough, if we let <span class="math inline">\(\Sigma_k = I \forall k\)</span>, we get K-means clustering.</p>
</section>
<section id="sampling-from-a-gaussian-mixture-model" class="level4">
<h4 class="anchored" data-anchor-id="sampling-from-a-gaussian-mixture-model">Sampling from a Gaussian Mixture Model</h4>
<p>To sample from a Gaussian Mixture Model, we break the process up into two steps:</p>
<ol type="1">
<li>Sample <span class="math inline">\(z^{(i)}\)</span> from a categorical distribution with probabilities <span class="math inline">\(\pi_k\)</span>. We want <span class="math inline">\(z^{(i)}\)</span> to be a one-hot encoded vector, where the <span class="math inline">\(k\)</span>-th element is 1 and all other elements are 0.</li>
<li>Sample <span class="math inline">\(x^{(i)}\)</span> from the <span class="math inline">\(k\)</span>-th Gaussian component that <span class="math inline">\(z^{(i)}\)</span> encodes for.</li>
</ol>
</section>
<section id="bayesian-approach" class="level4">
<h4 class="anchored" data-anchor-id="bayesian-approach">Bayesian approach</h4>
<p>Sometimes it’s hard to determine what is the ideal value for <span class="math inline">\(K\)</span> in a GMM, especially in higher dimensions. A Bayesian approach can be used to estimate the number of clusters. The math behind this goes beyond the scope of this chapter, but fortunately, Scikit-Learn has a Bayesian GMM implementation.</p>
</section>
<section id="kernel-density-estimation" class="level4">
<h4 class="anchored" data-anchor-id="kernel-density-estimation">Kernel Density Estimation</h4>
<p>We can use gaussian mixture models to estimate the probability density function of a random variable. This is called Kernel Density Estimation. It’s a bit more involved than GMM, but it’s a very useful tool for visually understanding the underlying distribution of a dataset.</p>
</section>
</section>
<section id="not-pytorch" class="level2">
<h2 class="anchored" data-anchor-id="not-pytorch">Not PyTorch</h2>
<section id="kernel-density-estimation-1" class="level4">
<h4 class="anchored" data-anchor-id="kernel-density-estimation-1">Kernel Density Estimation</h4>
<p>The penguin dataset is a popular dataset measuring several characteristics of penguins living on 3 different islands. Let’s use Kernel Density Estimation to get a better understanding of the underlying distribution of the dataset.</p>
<div id="6c8c3087" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Libraries and data</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> combinations</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> pairwise_distances</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture, BayesianGaussianMixture</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>color_pallete <span class="op">=</span> sns.color_palette(<span class="st">"hls"</span>, <span class="dv">10</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># penguins dataset</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> sns.load_dataset(<span class="st">'penguins'</span>).dropna()</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>numerical_columns <span class="op">=</span> df.select_dtypes(include<span class="op">=</span>[np.number]).columns</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>categorical_columns <span class="op">=</span> df.select_dtypes(include<span class="op">=</span>[<span class="bu">object</span>]).columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="306b7072" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>1D KDE plots</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.flatten()  <span class="co"># Flatten the array for easy iteration</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(numerical_columns):</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    sns.kdeplot(data<span class="op">=</span>df, x<span class="op">=</span>col, fill<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>axes[i])</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(col)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(col)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">'One-Dimensional KDE Plots for Penguin Data'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GausianMixture_files/figure-html/cell-3-output-1.png" class="quarto-figure quarto-figure-center figure-img" width="665" height="475"></p>
</figure>
</div>
</div>
</div>
<p>From the 1D KDE plots, we can see that the distributions of the numerical variables are not normal, and most have two peaks. Maybe one corresponds to female penguins and the other to male penguins.</p>
<div id="17febd86" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>2D KDE plots</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.flatten()  <span class="co"># Flatten the array for easy iteration</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot each 2D KDE in a subplot</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (x, y) <span class="kw">in</span> <span class="bu">enumerate</span>(combinations(numerical_columns, <span class="dv">2</span>)):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    sns.kdeplot(data<span class="op">=</span>df, x<span class="op">=</span>x, y<span class="op">=</span>y, fill<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>axes[i])</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="ss">f'</span><span class="sc">{</span>x<span class="sc">}</span><span class="ch">\n</span><span class="ss">vs </span><span class="sc">{</span>y<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(x)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(y)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">'Two-Dimensional KDE Plots for Penguin Data'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GausianMixture_files/figure-html/cell-4-output-1.png" class="quarto-figure quarto-figure-center figure-img" width="660" height="475"></p>
</figure>
</div>
</div>
</div>
<p>By analyzing the 2D KDE plots, we can see that the that all pair-wise distributions have at least 2 peaks, with some of them having 3 peaks. Maybe the clear 2 peaks correspond to female and male penguins, and the 3 peaks correspond to different species or islands. Let’s try to cluster the data to see if we can find any patterns.</p>
</section>
<section id="clustering" class="level4">
<h4 class="anchored" data-anchor-id="clustering">Clustering</h4>
<p>Fortunately, Scikit-learn provides an interface for clustering data using Gaussian Mixture Models (GMMs). It also provides an interface for a Bayesian GMM. Let’s fit both and compare the results. The GMM will have 3 components (as we saw 3 peaks in the 2D KDE plots), and the Bayesian GMM will have 9 components. We’ll use the same penguin dataset as before.</p>
<div id="00653298" class="cell" data-cache="true" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fit models</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> df.select_dtypes(include<span class="op">=</span>[np.number])</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>gaussian_clusters <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>).fit_predict(data)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>bayesian_clusters <span class="op">=</span> BayesianGaussianMixture(n_components<span class="op">=</span><span class="dv">9</span>, random_state<span class="op">=</span><span class="dv">42</span>).fit_predict(data)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># augment dataset</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'gaussian_clusters'</span>] <span class="op">=</span> gaussian_clusters</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'bayesian_clusters'</span>] <span class="op">=</span> bayesian_clusters</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Bayesian GMM has </span><span class="sc">{</span><span class="bu">len</span>(np.unique(bayesian_clusters))<span class="sc">}</span><span class="ss"> components'</span>)    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Bayesian GMM has 6 components</code></pre>
</div>
</div>
<p>The bayesian GMM ended with 5 components, which is less than the original suggestion of 9. This shows that a Bayesian GMM can automatically determine the number of components in the data.</p>
<p>Let’s now compare the incidence between categorical variables and the clusters, beginning with the GMM.</p>
<div id="ae47d610" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>GMM Incidences</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> cat <span class="kw">in</span> categorical_columns:</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    display(</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        df.groupby(by<span class="op">=</span>[<span class="st">'gaussian_clusters'</span>, cat]) <span class="op">\</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>          .size()<span class="op">\</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>          .unstack(fill_value<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">species</th>
<th data-quarto-table-cell-role="th">Adelie</th>
<th data-quarto-table-cell-role="th">Chinstrap</th>
<th data-quarto-table-cell-role="th">Gentoo</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">gaussian_clusters</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2</td>
<td>65</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0</td>
<td>0</td>
<td>119</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>144</td>
<td>3</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">island</th>
<th data-quarto-table-cell-role="th">Biscoe</th>
<th data-quarto-table-cell-role="th">Dream</th>
<th data-quarto-table-cell-role="th">Torgersen</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">gaussian_clusters</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>65</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>119</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>44</td>
<td>58</td>
<td>45</td>
</tr>
</tbody>
</table>

</div>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">sex</th>
<th data-quarto-table-cell-role="th">Female</th>
<th data-quarto-table-cell-role="th">Male</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">gaussian_clusters</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>31</td>
<td>36</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>58</td>
<td>61</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>76</td>
<td>71</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>We can observe that the clusters using a GMM match pretty well with the penguin species. This makes sense as different species have different characteristics, which are captured by the GMM. Now let’s take a look at the Bayesian GMM.</p>
<div id="092a6f6a" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Bayesian GMM Incidences</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> cat <span class="kw">in</span> categorical_columns:</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    display(</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        df.groupby(by<span class="op">=</span>[<span class="st">'bayesian_clusters'</span>, cat]) <span class="op">\</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>          .size() <span class="op">\</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>          .unstack(fill_value<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">species</th>
<th data-quarto-table-cell-role="th">Adelie</th>
<th data-quarto-table-cell-role="th">Chinstrap</th>
<th data-quarto-table-cell-role="th">Gentoo</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">bayesian_clusters</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>145</td>
<td>5</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>0</td>
<td>0</td>
<td>40</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>62</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>0</td>
<td>0</td>
<td>78</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">8</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">island</th>
<th data-quarto-table-cell-role="th">Biscoe</th>
<th data-quarto-table-cell-role="th">Dream</th>
<th data-quarto-table-cell-role="th">Torgersen</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">bayesian_clusters</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>44</td>
<td>60</td>
<td>46</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>40</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>0</td>
<td>62</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>78</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">8</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">sex</th>
<th data-quarto-table-cell-role="th">Female</th>
<th data-quarto-table-cell-role="th">Male</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">bayesian_clusters</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>78</td>
<td>72</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>0</td>
<td>40</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>28</td>
<td>35</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>58</td>
<td>20</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">8</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>First, let’s observe that clusters 7 and 8 have one observation each, these are likely outliers. Once again, the clusters match the penguin species pretty well. Moreover, there’s better correspondace with island (other than cluster 0) and cluster 2 is composed only by Males. While the bayesian GMM is a bit more complex, it seems to be a better fit for this dataset.</p>
</section>
<section id="testing-variational-autoencoders" class="level4">
<h4 class="anchored" data-anchor-id="testing-variational-autoencoders">Testing Variational Autoencoders</h4>
<p>So far, we’ve stated that Variational Autoencoders produce a latent space that is normaly distributed. GMM provide us with the tools needed to test this claim. During the semester I trained a VAE on the MNIST dataset with 10 latent features. Let’s see if the latent space is normaly distributed.</p>
<div id="9d9d353f" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Load and prepare data</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># read data</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>encodings <span class="op">=</span> np.loadtxt(<span class="st">'data/test_data.csv'</span>, delimiter<span class="op">=</span><span class="st">','</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> np.loadtxt(<span class="st">'data/test_labels.csv'</span>, delimiter<span class="op">=</span><span class="st">','</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># put data into dataframe</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(encodings)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'label'</span>] <span class="op">=</span> labels</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># format data in seaborn friendly format</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>df_long <span class="op">=</span> df.melt(</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    value_vars<span class="op">=</span><span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">10</span>)), </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    id_vars<span class="op">=</span>[<span class="st">'label'</span>], </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    var_name<span class="op">=</span><span class="st">'dimension'</span>, value_name<span class="op">=</span><span class="st">'value'</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>First, let’s take a look at the encoded space and the covariance matrix.</p>
<div id="acf3866c" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Unconditioned distribution of the latent space</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> save_distribution(df_long, covariance_matrix, title_suffix<span class="op">=</span><span class="st">''</span>):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># KDE Plot</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    sns.kdeplot(data<span class="op">=</span>df_long, x<span class="op">=</span><span class="st">'value'</span>, hue<span class="op">=</span><span class="st">'dimension'</span>, palette<span class="op">=</span>color_pallete, ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_title(<span class="st">'KDE Plot of Encodings'</span> <span class="op">+</span> title_suffix)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Covariance Heatmap</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(covariance_matrix, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">'RdYlGn'</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>], vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_title(<span class="st">'Covariance Matrix of Encodings'</span> <span class="op">+</span> title_suffix)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># save combined plot</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    filename <span class="op">=</span> <span class="ss">f'figures/distribution</span><span class="sc">{</span>title_suffix<span class="sc">}</span><span class="ss">.png'</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    filename <span class="op">=</span> filename.replace(<span class="st">' '</span>, <span class="st">'-'</span>).replace(<span class="st">','</span>, <span class="st">'-'</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    filename <span class="op">=</span> filename.replace(<span class="st">'('</span>, <span class="st">''</span>).replace(<span class="st">')'</span>, <span class="st">''</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    plt.savefig(filename, dpi<span class="op">=</span><span class="dv">300</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    plt.close()</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>save_distribution(df_long, df.drop(columns<span class="op">=</span>[<span class="st">'label'</span>]).cov(), title_suffix<span class="op">=</span><span class="st">', Unconditioned'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/distribution--Unconditioned.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%"></p>
</figure>
</div>
<p>From the plot on the left we can observe that each latent dimension is normally distributed, centered at. The covariance matrix on the right is essentially the identity matrix, showing that the dimensions are not correlated with each other. Putting these two statements together, each dimension is independently distributed with a standard normal. The VAE has indeed learned a normally distributed latent space.</p>
<p>Just for fun, let’s take a look at the distribution of the latent variables conditioned on the label.</p>
<div id="2e1117fa" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Distribution of the latent space conditioned on the label</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># encoded values for the given label</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    label_values <span class="op">=</span> df_long[df_long[<span class="st">'label'</span>] <span class="op">==</span> i]</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># covariance matrix for the given label</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    label_cov <span class="op">=</span> df[df[<span class="st">'label'</span>] <span class="op">==</span> i].drop(columns<span class="op">=</span>[<span class="st">'label'</span>]).cov()</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot the distribution</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    save_distribution(label_values, label_cov, title_suffix<span class="op">=</span><span class="ss">f', label = </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><img src="figures/distribution--label-=-0.png" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%"> <img src="figures/distribution--label-=-1.png" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%"> <img src="figures/distribution--label-=-2.png" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%"> <img src="figures/distribution--label-=-3.png" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%"> <img src="figures/distribution--label-=-4.png" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%"> <img src="figures/distribution--label-=-5.png" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%"> <img src="figures/distribution--label-=-6.png" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%"> <img src="figures/distribution--label-=-7.png" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%"> <img src="figures/distribution--label-=-8.png" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%"> <img src="figures/distribution--label-=-9.png" class="img-fluid quarto-figure quarto-figure-center" style="width:90.0%"></p>
<p>We can see that the distributions are different for different labels and while they look mostly normal, their covariance matrices, show that their dimensions are not independent. So, unconditionally, the dimensions are independent, but conditionally, they’re dependent - the opposite of the assumptions for a Naive Bayes’ Classifier.</p>
<hr>
<p>In this section we’ve explored Gaussian Mixtures and how they can be used to model the distribution of real data. We’ve also seen how they can be used to perform clustering and classification. This is an important tool to consider when trying to understand the data before applying more advanced techniques.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>